# FastIE

<p align="center">
    <a href="https://github.com/xusenlinzy/fastie"><img src="https://img.shields.io/github/license/xusenlinzy/fastie"></a>
    <a href=""><img src="https://img.shields.io/badge/python-3.8+-aff.svg"></a>
    <a href=""><img src="https://img.shields.io/badge/pytorch-%3E=1.12-red?logo=pytorch"></a>
    <a href="https://github.com/xusenlinzy/fastie"><img src="https://img.shields.io/github/last-commit/xusenlinzy/fastie"></a>
    <a href="https://github.com/xusenlinzy/fastie"><img src="https://img.shields.io/github/issues/xusenlinzy/fastie?color=9cc"></a>
    <a href="https://github.com/xusenlinzy/fastie"><img src="https://img.shields.io/github/stars/xusenlinzy/fastie?color=ccf"></a>
    <a href="https://github.com/xusenlinzy/fastie"><img src="https://img.shields.io/badge/langurage-py-brightgreen?style=flat&color=blue"></a>
</p>

æ­¤é¡¹ç›®ä¸ºå¼€æº**æ–‡æœ¬åˆ†ç±»ã€å®ä½“æŠ½å–ã€å…³ç³»æŠ½å–å’Œäº‹ä»¶æŠ½å–**æ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†æä¾›ç»Ÿä¸€çš„æ¡†æ¶ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹æ€§


+ âœ¨ æ”¯æŒå¤šç§å¼€æºæ–‡æœ¬åˆ†ç±»ã€å®ä½“æŠ½å–ã€å…³ç³»æŠ½å–å’Œäº‹ä»¶æŠ½å–æ¨¡å‹


+ ğŸ‘‘ æ”¯æŒç™¾åº¦ [UIE](https://github.com/PaddlePaddle/PaddleNLP) æ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†


+ ğŸš€ ç»Ÿä¸€çš„è®­ç»ƒå’Œæ¨ç†æ¡†æ¶


+ ğŸ¯ é›†æˆå¯¹æŠ—è®­ç»ƒæ–¹æ³•ï¼Œç®€ä¾¿æ˜“ç”¨


## ğŸ“¢ News 

+ ã€2024.8.30ã€‘ å‘å¸ƒåˆå§‹ç‰ˆæœ¬


---

## ğŸ“¦ å®‰è£…


```shell
pip install --upgrade fastie
```

## ğŸ¼ ä¸»è¦æ¨¡å‹

### å®ä½“æŠ½å–

| æ¨¡å‹             | è®ºæ–‡                                                                                                                                                                            | å¤‡æ³¨                                                                                                                                            |
|----------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------|
| softmax        |                                                                                                                                                                               | å…¨è¿æ¥å±‚åºåˆ—æ ‡æ³¨å¹¶ä½¿ç”¨ `BIO` è§£ç                                                                                                                           |
| crf            | [Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data](https://repository.upenn.edu/cgi/viewcontent.cgi?article=1162&context=cis_papers) | å…¨è¿æ¥å±‚+æ¡ä»¶éšæœºåœºï¼Œå¹¶ä½¿ç”¨ `BIO` è§£ç                                                                                                                        |
| cascade-crf    |                                                                                                                                                                               | å…ˆé¢„æµ‹å®ä½“å†é¢„æµ‹å®ä½“ç±»å‹                                                                                                                                  |
| span           |                                                                                                                                                                               | ä½¿ç”¨ä¸¤ä¸ªæŒ‡é’ˆç½‘ç»œé¢„æµ‹å®ä½“èµ·å§‹ä½ç½®                                                                                                                              |
| global-pointer |                                                                                                                                                                               | [GlobalPointerï¼šç”¨ç»Ÿä¸€çš„æ–¹å¼å¤„ç†åµŒå¥—å’ŒéåµŒå¥—NER](https://spaces.ac.cn/archives/8373)ã€[Efficient GlobalPointerï¼šå°‘ç‚¹å‚æ•°ï¼Œå¤šç‚¹æ•ˆæœ](https://spaces.ac.cn/archives/8877) |
| tplinker       | [TPLinker: Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking.](https://aclanthology.org/2020.coling-main.138.pdf)                            | å°†å®ä½“è¯†åˆ«ä»»åŠ¡è½¬æ¢ä¸ºè¡¨æ ¼å¡«å……é—®é¢˜                                                                                                                              |
| w2ner          | [Unified Named Entity Recognition as Word-Word Relation Classification.](https://arxiv.org/pdf/2112.10070.pdf)                                                                | ç»Ÿä¸€è§£å†³åµŒå¥—å®ä½“ã€ä¸è¿ç»­å®ä½“çš„æŠ½å–é—®é¢˜                                                                                                                           |
| cnn            | [An Embarrassingly Easy but Strong Baseline for Nested Named Entity Recognition.](https://arxiv.org/abs/2208.04534)                                                           | æ”¹è¿› `W2NER` æ–¹æ³•ï¼Œé‡‡ç”¨å·ç§¯ç½‘ç»œæå–å®ä½“å†…éƒ¨tokenä¹‹é—´çš„å…³ç³»                                                                                                          |


### å…³ç³»æŠ½å–

| æ¨¡å‹       | è®ºæ–‡                                                                                                                                                 | å¤‡æ³¨                                                                  |
|----------|----------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------|
| casrel   | [A Novel Cascade Binary Tagging Framework for Relational Triple Extraction.](https://aclanthology.org/2020.acl-main.136.pdf)                       | ä¸¤é˜¶æ®µå…³ç³»æŠ½å–ï¼Œå…ˆæŠ½å–å‡ºå¥å­ä¸­çš„ä¸»è¯­ï¼Œå†é€šè¿‡æŒ‡é’ˆç½‘ç»œæŠ½å–å‡ºä¸»è¯­å¯¹åº”çš„å…³ç³»å’Œå®¾è¯­                             |
| tplinker | [TPLinker: Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking.](https://aclanthology.org/2020.coling-main.138.pdf) | å°†å…³ç³»æŠ½å–é—®é¢˜è½¬æ¢ä¸ºä¸»è¯­-å®¾è¯­çš„é¦–å°¾è¿æ¥é—®é¢˜                                              |
| spn      | [Joint Entity and Relation Extraction with Set Prediction Networks.](http://xxx.itp.ac.cn/pdf/2011.01675v2)                                        | å°†å…³ç³»æŠ½å–é—®é¢˜è½¬ä¸ºä¸ºä¸‰å…ƒç»„çš„é›†åˆé¢„æµ‹é—®é¢˜ï¼Œé‡‡ç”¨ `Encoder-Decoder` æ¡†æ¶                        |
| prgc     | [PRGC: Potential Relation and Global Correspondence Based Joint Relational Triple Extraction.](https://aclanthology.org/2021.acl-long.486.pdf)     | å…ˆæŠ½å–å¥å­çš„æ½œåœ¨å…³ç³»ç±»å‹ï¼Œç„¶åå¯¹äºç»™å®šå…³ç³»æŠ½å–å‡ºå¯¹åº”çš„ä¸»è¯­-å®¾è¯­å¯¹ï¼Œæœ€åé€šè¿‡å…¨å±€å¯¹é½æ¨¡å—è¿‡æ»¤                      |
| pfn      | [A Partition Filter Network for Joint Entity and Relation Extraction.](https://aclanthology.org/2021.emnlp-main.17.pdf)                            | é‡‡ç”¨ç±»ä¼¼  `LSTM`  çš„åˆ†åŒºè¿‡æ»¤æœºåˆ¶ï¼Œå°†éšè—å±‚ä¿¡æ¯åˆ†æˆå®ä½“è¯†åˆ«ã€å…³ç³»è¯†åˆ«å’Œå…±äº«ä¸‰éƒ¨åˆ†ï¼Œå¯¹ä¸ä¸åŒçš„ä»»åŠ¡åˆ©ç”¨ä¸åŒçš„ä¿¡æ¯        |
| grte     | [A Novel Global Feature-Oriented Relational Triple Extraction Model based on Table Filling.](https://aclanthology.org/2021.emnlp-main.208.pdf)     | å°†å…³ç³»æŠ½å–é—®é¢˜è½¬æ¢ä¸ºå•è¯å¯¹çš„åˆ†ç±»é—®é¢˜ï¼ŒåŸºäºå…¨å±€ç‰¹å¾æŠ½å–æ¨¡å—å¾ªç¯ä¼˜åŒ–å•è¯å¯¹çš„å‘é‡è¡¨ç¤º                           |
| gplinker |                                                                                                                                                    | [GPLinkerï¼šåŸºäºGlobalPointerçš„å®ä½“å…³ç³»è”åˆæŠ½å–](https://kexue.fm/archives/8888) |


## ğŸ“š æ•°æ®

### å®ä½“æŠ½å–

å°†æ•°æ®é›†å¤„ç†æˆä»¥ä¸‹ `json` æ ¼å¼

```json
{
  "text": "ç»“æœä¸Šå‘¨å…­ä»–ä»¬ä¸»åœº0ï¼š3æƒ¨è´¥ç»™äº†ä¸­æ¸¸çƒé˜Ÿç“¦æ‹‰å¤šåˆ©å¾·ï¼Œè¿‘7ä¸ªå¤šæœˆä»¥æ¥è¥¿ç”²é¦–æ¬¡è¾“çƒã€‚", 
  "entities": [
    {
      "id": 0, 
      "entity": "ç“¦æ‹‰å¤šåˆ©å¾·", 
      "start_offset": 20, 
      "end_offset": 25, 
      "label": "organization"
    }, 
    {
      "id": 1, 
      "entity": "è¥¿ç”²", 
      "start_offset": 33, 
      "end_offset": 35, 
      "label": "organization"
    }
  ]
}
```

å­—æ®µå«ä¹‰ï¼š

+ `text`: æ–‡æœ¬å†…å®¹

+ `entities`: è¯¥æ–‡æœ¬æ‰€åŒ…å«çš„æ‰€æœ‰å®ä½“

    + `id`: å®ä½“ `id`

    + `entity`: å®ä½“åç§°
  
    + `start_offset`: å®ä½“å¼€å§‹ä½ç½®

    + `end_offset`: å®ä½“ç»“æŸä½ç½®çš„ä¸‹ä¸€ä½

    + `label`: å®ä½“ç±»å‹


### å…³ç³»æŠ½å–

å°†æ•°æ®é›†å¤„ç†æˆä»¥ä¸‹ `json` æ ¼å¼

```json
{
  "text": "æŸ¥å°”æ–¯Â·é˜¿å…°åŸºæ–¯ï¼ˆCharles ArÃ¡nguizï¼‰ï¼Œ1989å¹´4æœˆ17æ—¥å‡ºç”Ÿäºæ™ºåˆ©åœ£åœ°äºšå“¥ï¼Œæ™ºåˆ©èŒä¸šè¶³çƒè¿åŠ¨å‘˜ï¼Œå¸èŒä¸­åœºï¼Œæ•ˆåŠ›äºå¾·å›½è¶³çƒç”²çº§è”èµ›å‹’æ²ƒåº“æ£®è¶³çƒä¿±ä¹éƒ¨", 
  "spo_list": [
    {
      "predicate": "å‡ºç”Ÿåœ°",
      "object": "åœ£åœ°äºšå“¥", 
      "subject": "æŸ¥å°”æ–¯Â·é˜¿å…°åŸºæ–¯"
    }, 
    {
      "predicate": "å‡ºç”Ÿæ—¥æœŸ",
      "object": "1989å¹´4æœˆ17æ—¥",
      "subject": "æŸ¥å°”æ–¯Â·é˜¿å…°åŸºæ–¯"
    }
  ]
}
```

å­—æ®µå«ä¹‰ï¼š

+ `text`: æ–‡æœ¬å†…å®¹

+ `spo_list`: è¯¥æ–‡æœ¬æ‰€åŒ…å«çš„æ‰€æœ‰å…³ç³»ä¸‰å…ƒç»„

    + `subject`: ä¸»ä½“åç§°

    + `object`: å®¢ä½“åç§°
  
    + `predicate`: ä¸»ä½“å’Œå®¢ä½“ä¹‹é—´çš„å…³ç³»


### äº‹ä»¶æŠ½å–

å°†æ•°æ®é›†å¤„ç†æˆä»¥ä¸‹ `json` æ ¼å¼

```json
{
  "text": "æ²¹æœå·¨å¤´å“ˆé‡Œä¼¯é¡¿è£å‘˜650äºº å› ç¾å›½æ²¹æ°”å¼€é‡‡æ´»åŠ¨æ”¾ç¼“",
  "id": "f2d936214dc2cb1b873a75ee29a30ec9",
  "event_list": [
    {
      "event_type": "ç»„ç»‡å…³ç³»-è£å‘˜",
      "trigger": "è£å‘˜",
      "trigger_start_index": 8,
      "arguments": [
        {
          "argument_start_index": 0,
          "role": "è£å‘˜æ–¹",
          "argument": "æ²¹æœå·¨å¤´å“ˆé‡Œä¼¯é¡¿"
        },
        {
          "argument_start_index": 10,
          "role": "è£å‘˜äººæ•°",
          "argument": "650äºº"
        }
      ],
      "class": "ç»„ç»‡å…³ç³»"
    }
  ]
}
```

å­—æ®µå«ä¹‰ï¼š

+ `text`: æ–‡æœ¬å†…å®¹

+ `event_list`: è¯¥æ–‡æœ¬æ‰€åŒ…å«çš„æ‰€æœ‰äº‹ä»¶

    + `event_type`: äº‹ä»¶ç±»å‹

    + `trigger`: è§¦å‘è¯
  
    + `trigger_start_index`: è§¦å‘è¯å¼€å§‹ä½ç½®

    + `arguments`: è®ºå…ƒ
  
        + `role`: è®ºå…ƒè§’è‰²
      
        + `argument`: è®ºå…ƒåç§°
      
        + `argument_start_index`: è®ºå…ƒåç§°å¼€å§‹ä½ç½®
  
## ğŸš€ æ¨¡å‹è®­ç»ƒ

### å®ä½“æŠ½å–

```shell
python -m fastie.cli examples/named_entity_recognition/global_pointer.yaml
```

è®­ç»ƒè„šæœ¬è¯¦è§ [named_entity_recognition](./examples/named_entity_recognition)

### å…³ç³»æŠ½å–

```shell
python -m fastie.cli examples/named_entity_recognition/gplinker.yaml
```

è®­ç»ƒè„šæœ¬è¯¦è§ [relation_extraction](./examples/relation_extraction)


### äº‹ä»¶æŠ½å–

```shell
python -m fastie.cli examples/event_extraction/gplinker.yaml
```

è®­ç»ƒè„šæœ¬è¯¦è§ [event_extraction](./examples/event_extraction)


## ğŸ“Š æ¨¡å‹æ¨ç†

```python
from transformers import AutoModel, AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("path_to_model", trust_remote_code=True)
model = AutoModel.from_pretrained("path_to_model", trust_remote_code=True)

print(model.predict(tokenizer, "å› è‚ºè¿‡åº¦å……æ°”ï¼Œå¸¸å°†è‚è„æ¨å‘ä¸‹æ–¹ã€‚"))
```


## ğŸ­ é€šç”¨ä¿¡æ¯æŠ½å–

+ [UIE(Universal Information Extraction)](https://arxiv.org/pdf/2203.12277.pdf)ï¼šYaojie Luç­‰äººåœ¨ACL-2022ä¸­æå‡ºäº†é€šç”¨ä¿¡æ¯æŠ½å–ç»Ÿä¸€æ¡†æ¶ `UIE`ã€‚


+ è¯¥æ¡†æ¶å®ç°äº†å®ä½“æŠ½å–ã€å…³ç³»æŠ½å–ã€äº‹ä»¶æŠ½å–ã€æƒ…æ„Ÿåˆ†æç­‰ä»»åŠ¡çš„ç»Ÿä¸€å»ºæ¨¡ï¼Œå¹¶ä½¿å¾—ä¸åŒä»»åŠ¡é—´å…·å¤‡è‰¯å¥½çš„è¿ç§»å’Œæ³›åŒ–èƒ½åŠ›ã€‚


+ [PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)å€Ÿé‰´è¯¥è®ºæ–‡çš„æ–¹æ³•ï¼ŒåŸºäº `ERNIE 3.0` çŸ¥è¯†å¢å¼ºé¢„è®­ç»ƒæ¨¡å‹ï¼Œè®­ç»ƒå¹¶å¼€æºäº†é¦–ä¸ªä¸­æ–‡é€šç”¨ä¿¡æ¯æŠ½å–æ¨¡å‹ `UIE`ã€‚


+ è¯¥æ¨¡å‹å¯ä»¥æ”¯æŒä¸é™å®šè¡Œä¸šé¢†åŸŸå’ŒæŠ½å–ç›®æ ‡çš„å…³é”®ä¿¡æ¯æŠ½å–ï¼Œå®ç°é›¶æ ·æœ¬å¿«é€Ÿå†·å¯åŠ¨ï¼Œå¹¶å…·å¤‡ä¼˜ç§€çš„å°æ ·æœ¬å¾®è°ƒèƒ½åŠ›ï¼Œå¿«é€Ÿé€‚é…ç‰¹å®šçš„æŠ½å–ç›®æ ‡ã€‚


### æ¨¡å‹è®­ç»ƒ

æ¨¡å‹è®­ç»ƒè„šæœ¬è¯¦è§ [uie](./examples/uie)

### æ¨¡å‹æ¨ç†

<details>
<summary>ğŸ‘‰ å‘½åå®ä½“è¯†åˆ«</summary>

```python
from transformers import AutoModel, AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("xusenlin/uie-base", trust_remote_code=True)
model = AutoModel.from_pretrained("xusenlin/uie-base", trust_remote_code=True)

schema = ["æ—¶é—´", "é€‰æ‰‹", "èµ›äº‹åç§°"]  # Define the schema for entity extraction
print(model.predict(tokenizer, "2æœˆ8æ—¥ä¸ŠåˆåŒ—äº¬å†¬å¥¥ä¼šè‡ªç”±å¼æ»‘é›ªå¥³å­å¤§è·³å°å†³èµ›ä¸­ä¸­å›½é€‰æ‰‹è°·çˆ±å‡Œä»¥188.25åˆ†è·å¾—é‡‘ç‰Œï¼", schema=schema))
```

output: 

```json
[
  {
    "æ—¶é—´": [
      {
        "end": 6,
        "probability": 0.98573786,
        "start": 0,
        "text": "2æœˆ8æ—¥ä¸Šåˆ"
      }
    ],
    "èµ›äº‹åç§°": [
      {
        "end": 23,
        "probability": 0.8503085,
        "start": 6,
        "text": "åŒ—äº¬å†¬å¥¥ä¼šè‡ªç”±å¼æ»‘é›ªå¥³å­å¤§è·³å°å†³èµ›"
      }
    ],
    "é€‰æ‰‹": [
      {
        "end": 31,
        "probability": 0.8981544,
        "start": 28,
        "text": "è°·çˆ±å‡Œ"
      }
    ]
  }
]
```
</details>

<details>
<summary>ğŸ‘‰ å®ä½“å…³ç³»æŠ½å–</summary>

```python
schema = {'ç«èµ›åç§°': ['ä¸»åŠæ–¹', 'æ‰¿åŠæ–¹', 'å·²ä¸¾åŠæ¬¡æ•°']}  # Define the schema for relation extraction
model.set_schema(schema)
print(model.predict(tokenizer, "2022è¯­è¨€ä¸æ™ºèƒ½æŠ€æœ¯ç«èµ›ç”±ä¸­å›½ä¸­æ–‡ä¿¡æ¯å­¦ä¼šå’Œä¸­å›½è®¡ç®—æœºå­¦ä¼šè”åˆä¸»åŠï¼Œç™¾åº¦å…¬å¸ã€ä¸­å›½ä¸­æ–‡ä¿¡æ¯å­¦ä¼šè¯„æµ‹å·¥ä½œå§”å‘˜ä¼šå’Œä¸­å›½è®¡ç®—æœºå­¦ä¼šè‡ªç„¶è¯­è¨€å¤„ç†ä¸“å§”ä¼šæ‰¿åŠï¼Œå·²è¿ç»­ä¸¾åŠ4å±Šï¼Œæˆä¸ºå…¨çƒæœ€çƒ­é—¨çš„ä¸­æ–‡NLPèµ›äº‹ä¹‹ä¸€ã€‚"))
```

output:

```json
[
  {
    "ç«èµ›åç§°": [
      {
        "end": 13,
        "probability": 0.78253937,
        "relations": {
          "ä¸»åŠæ–¹": [
            {
              "end": 22,
              "probability": 0.8421704,
              "start": 14,
              "text": "ä¸­å›½ä¸­æ–‡ä¿¡æ¯å­¦ä¼š"
            },
            {
              "end": 30,
              "probability": 0.75807965,
              "start": 23,
              "text": "ä¸­å›½è®¡ç®—æœºå­¦ä¼š"
            }
          ],
          "å·²ä¸¾åŠæ¬¡æ•°": [
            {
              "end": 82,
              "probability": 0.4671307,
              "start": 80,
              "text": "4å±Š"
            }
          ],
          "æ‰¿åŠæ–¹": [
            {
              "end": 55,
              "probability": 0.700049,
              "start": 40,
              "text": "ä¸­å›½ä¸­æ–‡ä¿¡æ¯å­¦ä¼šè¯„æµ‹å·¥ä½œå§”å‘˜ä¼š"
            },
            {
              "end": 72,
              "probability": 0.61934763,
              "start": 56,
              "text": "ä¸­å›½è®¡ç®—æœºå­¦ä¼šè‡ªç„¶è¯­è¨€å¤„ç†ä¸“å§”ä¼š"
            },
            {
              "end": 39,
              "probability": 0.8292698,
              "start": 35,
              "text": "ç™¾åº¦å…¬å¸"
            }
          ]
        },
        "start": 0,
        "text": "2022è¯­è¨€ä¸æ™ºèƒ½æŠ€æœ¯ç«èµ›"
      }
    ]
  }
]
```
</details>


<details>
<summary>ğŸ‘‰  äº‹ä»¶æŠ½å–</summary>

```python
schema = {'åœ°éœ‡è§¦å‘è¯': ['åœ°éœ‡å¼ºåº¦', 'æ—¶é—´', 'éœ‡ä¸­ä½ç½®', 'éœ‡æºæ·±åº¦']}  # Define the schema for event extraction
model.set_schema(schema)
print(model.predict(tokenizer, "ä¸­å›½åœ°éœ‡å°ç½‘æ­£å¼æµ‹å®šï¼š5æœˆ16æ—¥06æ—¶08åˆ†åœ¨äº‘å—ä¸´æ²§å¸‚å‡¤åº†å¿(åŒ—çº¬24.34åº¦ï¼Œä¸œç»99.98åº¦)å‘ç”Ÿ3.5çº§åœ°éœ‡ï¼Œéœ‡æºæ·±åº¦10åƒç±³ã€‚"))
```

output:

```json
[
  {
    "åœ°éœ‡è§¦å‘è¯": [
      {
        "end": 58,
        "probability": 0.99774253,
        "relations": {
          "åœ°éœ‡å¼ºåº¦": [
            {
              "end": 56,
              "probability": 0.9980802,
              "start": 52,
              "text": "3.5çº§"
            }
          ],
          "æ—¶é—´": [
            {
              "end": 22,
              "probability": 0.98533,
              "start": 11,
              "text": "5æœˆ16æ—¥06æ—¶08åˆ†"
            }
          ],
          "éœ‡ä¸­ä½ç½®": [
            {
              "end": 50,
              "probability": 0.7874015,
              "start": 23,
              "text": "äº‘å—ä¸´æ²§å¸‚å‡¤åº†å¿(åŒ—çº¬24.34åº¦ï¼Œä¸œç»99.98åº¦)"
            }
          ],
          "éœ‡æºæ·±åº¦": [
            {
              "end": 67,
              "probability": 0.9937973,
              "start": 63,
              "text": "10åƒç±³"
            }
          ]
        },
        "start": 56,
        "text": "åœ°éœ‡"
      }
    ]
  }
]
```
</details>

<details>
<summary>ğŸ‘‰ è¯„è®ºè§‚ç‚¹æŠ½å–</summary>

```python
schema = {'è¯„ä»·ç»´åº¦': ['è§‚ç‚¹è¯', 'æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]']}  # Define the schema for opinion extraction
model.set_schema(schema)
print(model.predict(tokenizer, "åº—é¢å¹²å‡€ï¼Œå¾ˆæ¸…é™ï¼ŒæœåŠ¡å‘˜æœåŠ¡çƒ­æƒ…ï¼Œæ€§ä»·æ¯”å¾ˆé«˜ï¼Œå‘ç°æ”¶é“¶å°æœ‰æ’é˜Ÿ"))
```

output:

```json
[
  {
    "è¯„ä»·ç»´åº¦": [
      {
        "end": 20,
        "probability": 0.98170394,
        "relations": {
          "æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]": [
            {
              "probability": 0.9966142773628235,
              "text": "æ­£å‘"
            }
          ],
          "è§‚ç‚¹è¯": [
            {
              "end": 22,
              "probability": 0.95739645,
              "start": 21,
              "text": "é«˜"
            }
          ]
        },
        "start": 17,
        "text": "æ€§ä»·æ¯”"
      },
      {
        "end": 2,
        "probability": 0.9696847,
        "relations": {
          "æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]": [
            {
              "probability": 0.9982153177261353,
              "text": "æ­£å‘"
            }
          ],
          "è§‚ç‚¹è¯": [
            {
              "end": 4,
              "probability": 0.9945317,
              "start": 2,
              "text": "å¹²å‡€"
            }
          ]
        },
        "start": 0,
        "text": "åº—é¢"
      }
    ]
  }
]
```
</details>


<details>
<summary>ğŸ‘‰ æƒ…æ„Ÿåˆ†ç±»</summary>


```python
schema = "æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]"  # Define the schema for opinion extraction
model.set_schema(schema)
print(model.predict(tokenizer, "è¿™ä¸ªäº§å“ç”¨èµ·æ¥çœŸçš„å¾ˆæµç•…ï¼Œæˆ‘éå¸¸å–œæ¬¢"))
```

output:

```json
[
  {
    "æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]": [
      {
        "probability": 0.9990023970603943,
        "text": "æ­£å‘"
      }
    ]
  }
]
```
</details>
