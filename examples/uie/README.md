## UIE

## æ¨¡å‹ä¸‹è½½

```python
from fastie.models.uie.convert import convert_uie_checkpoint

convert_uie_checkpoint("uie-base", "uie_base_pytorch")
```

### æ•°æ®æ ‡æ³¨

æˆ‘ä»¬æ¨èä½¿ç”¨æ•°æ®æ ‡æ³¨å¹³å° `doccano` è¿›è¡Œæ•°æ®æ ‡æ³¨ï¼Œæœ¬ç¤ºä¾‹ä¹Ÿæ‰“é€šäº†ä»æ ‡æ³¨åˆ°è®­ç»ƒçš„é€šé“ï¼Œå³ `doccano` å¯¼å‡ºæ•°æ®åå¯é€šè¿‡ `doccano.py` è„šæœ¬è½»æ¾å°†æ•°æ®è½¬æ¢ä¸ºè¾“å…¥æ¨¡å‹æ—¶éœ€è¦çš„å½¢å¼ï¼Œå®ç°æ— ç¼è¡”æ¥ã€‚

æ ‡æ³¨å®Œæˆåï¼Œä½¿ç”¨ä¸‹é¢å‘½ä»¤å°†æ•°æ®è¿›è¡Œå¤„ç†

```bash
python examples/uie/doccano.py \
     --doccano_file examples/uie/datasets/DuIE/doccano_ext.json \
    --save_dir examples/uie/datasets/DuIE 
```

å‚æ•°è¯´æ˜ï¼š

+ `doccano_file`: ä» `doccano` å¯¼å‡ºçš„æ•°æ®æ ‡æ³¨æ–‡ä»¶


+ `save_dir`: è®­ç»ƒæ•°æ®çš„ä¿å­˜ç›®å½•ï¼Œé»˜è®¤å­˜å‚¨åœ¨ `data` ç›®å½•ä¸‹


+ `negative_ratio`: æœ€å¤§è´Ÿä¾‹æ¯”ä¾‹ï¼Œè¯¥å‚æ•°åªå¯¹æŠ½å–ç±»å‹ä»»åŠ¡æœ‰æ•ˆï¼Œé€‚å½“æ„é€ è´Ÿä¾‹å¯æå‡æ¨¡å‹æ•ˆæœã€‚è´Ÿä¾‹æ•°é‡å’Œå®é™…çš„æ ‡ç­¾æ•°é‡æœ‰å…³ï¼Œæœ€å¤§è´Ÿä¾‹æ•°é‡ = `negative_ratio` * æ­£ä¾‹æ•°é‡ã€‚è¯¥å‚æ•°åªå¯¹è®­ç»ƒé›†æœ‰æ•ˆï¼Œé»˜è®¤ä¸º `5`ã€‚ä¸ºäº†ä¿è¯è¯„ä¼°æŒ‡æ ‡çš„å‡†ç¡®æ€§ï¼ŒéªŒè¯é›†å’Œæµ‹è¯•é›†é»˜è®¤æ„é€ å…¨è´Ÿä¾‹


+ `splits`: åˆ’åˆ†æ•°æ®é›†æ—¶è®­ç»ƒé›†ã€éªŒè¯é›†æ‰€å çš„æ¯”ä¾‹ã€‚é»˜è®¤ä¸º `[0.8, 0.1, 0.1]` è¡¨ç¤ºæŒ‰ç…§ `8:1:1` çš„æ¯”ä¾‹å°†æ•°æ®åˆ’åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†


+ `task_type`: é€‰æ‹©ä»»åŠ¡ç±»å‹ï¼Œå¯é€‰æœ‰æŠ½å–å’Œåˆ†ç±»ä¸¤ç§ç±»å‹çš„ä»»åŠ¡


+ `options`: æŒ‡å®šåˆ†ç±»ä»»åŠ¡çš„ç±»åˆ«æ ‡ç­¾ï¼Œè¯¥å‚æ•°åªå¯¹åˆ†ç±»ç±»å‹ä»»åŠ¡æœ‰æ•ˆã€‚é»˜è®¤ä¸º `["æ­£å‘", "è´Ÿå‘"]`


+ `prompt_prefix`: å£°æ˜åˆ†ç±»ä»»åŠ¡çš„ `prompt` å‰ç¼€ä¿¡æ¯ï¼Œè¯¥å‚æ•°åªå¯¹åˆ†ç±»ç±»å‹ä»»åŠ¡æœ‰æ•ˆã€‚é»˜è®¤ä¸º "æƒ…æ„Ÿå€¾å‘"


+ `is_shuffle`: æ˜¯å¦å¯¹æ•°æ®é›†è¿›è¡Œéšæœºæ‰“æ•£ï¼Œé»˜è®¤ä¸º `True`


+ `seed`: éšæœºç§å­ï¼Œé»˜è®¤ä¸º `1000`


+ `separator`: å®ä½“ç±»åˆ«/è¯„ä»·ç»´åº¦ä¸åˆ†ç±»æ ‡ç­¾çš„åˆ†éš”ç¬¦ï¼Œè¯¥å‚æ•°åªå¯¹å®ä½“/è¯„ä»·ç»´åº¦çº§åˆ†ç±»ä»»åŠ¡æœ‰æ•ˆã€‚é»˜è®¤ä¸º `"##"`


+ `schema_lang`: é€‰æ‹© `schema` çš„è¯­è¨€ï¼Œå¯é€‰æœ‰ `ch` å’Œ `en`ã€‚é»˜è®¤ä¸º `ch`ï¼Œè‹±æ–‡æ•°æ®é›†è¯·é€‰æ‹© `en`


å¤„ç†ä¹‹åçš„æ•°æ®ç¤ºä¾‹å¦‚ä¸‹

```json
{
  "content": "ç‹å›½ç»´ï¼Œå­—é™å®‰ï¼Œåˆå­—ä¼¯éš…ï¼Œå·è§‚å ‚",
  "result_list": [
    {
      "text": "è§‚å ‚",
      "start": 14,
      "end": 16
    }
  ],
  "prompt": "ç‹å›½ç»´çš„å·"
}
```

### æ¨¡å‹å¾®è°ƒ

```shell
fastie-cli train uie.yaml
```

### æ¨¡å‹æ¨ç†

<details>
<summary>ğŸ‘‰ å‘½åå®ä½“è¯†åˆ«</summary>

```python
from transformers import AutoModel, AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("xusenlin/uie-base", trust_remote_code=True)
model = AutoModel.from_pretrained("xusenlin/uie-base", trust_remote_code=True)

schema = ["æ—¶é—´", "é€‰æ‰‹", "èµ›äº‹åç§°"]  # Define the schema for entity extraction
print(model.predict(tokenizer, "2æœˆ8æ—¥ä¸ŠåˆåŒ—äº¬å†¬å¥¥ä¼šè‡ªç”±å¼æ»‘é›ªå¥³å­å¤§è·³å°å†³èµ›ä¸­ä¸­å›½é€‰æ‰‹è°·çˆ±å‡Œä»¥188.25åˆ†è·å¾—é‡‘ç‰Œï¼", schema=schema))
```

output: 

```json
[
  {
    "æ—¶é—´": [
      {
        "end": 6,
        "probability": 0.98573786,
        "start": 0,
        "text": "2æœˆ8æ—¥ä¸Šåˆ"
      }
    ],
    "èµ›äº‹åç§°": [
      {
        "end": 23,
        "probability": 0.8503085,
        "start": 6,
        "text": "åŒ—äº¬å†¬å¥¥ä¼šè‡ªç”±å¼æ»‘é›ªå¥³å­å¤§è·³å°å†³èµ›"
      }
    ],
    "é€‰æ‰‹": [
      {
        "end": 31,
        "probability": 0.8981544,
        "start": 28,
        "text": "è°·çˆ±å‡Œ"
      }
    ]
  }
]
```
</details>

<details>
<summary>ğŸ‘‰ å®ä½“å…³ç³»æŠ½å–</summary>

```python
schema = {'ç«èµ›åç§°': ['ä¸»åŠæ–¹', 'æ‰¿åŠæ–¹', 'å·²ä¸¾åŠæ¬¡æ•°']}  # Define the schema for relation extraction
model.set_schema(schema)
print(model.predict(tokenizer, "2022è¯­è¨€ä¸æ™ºèƒ½æŠ€æœ¯ç«èµ›ç”±ä¸­å›½ä¸­æ–‡ä¿¡æ¯å­¦ä¼šå’Œä¸­å›½è®¡ç®—æœºå­¦ä¼šè”åˆä¸»åŠï¼Œç™¾åº¦å…¬å¸ã€ä¸­å›½ä¸­æ–‡ä¿¡æ¯å­¦ä¼šè¯„æµ‹å·¥ä½œå§”å‘˜ä¼šå’Œä¸­å›½è®¡ç®—æœºå­¦ä¼šè‡ªç„¶è¯­è¨€å¤„ç†ä¸“å§”ä¼šæ‰¿åŠï¼Œå·²è¿ç»­ä¸¾åŠ4å±Šï¼Œæˆä¸ºå…¨çƒæœ€çƒ­é—¨çš„ä¸­æ–‡NLPèµ›äº‹ä¹‹ä¸€ã€‚"))
```

output:

```json
[
  {
    "ç«èµ›åç§°": [
      {
        "end": 13,
        "probability": 0.78253937,
        "relations": {
          "ä¸»åŠæ–¹": [
            {
              "end": 22,
              "probability": 0.8421704,
              "start": 14,
              "text": "ä¸­å›½ä¸­æ–‡ä¿¡æ¯å­¦ä¼š"
            },
            {
              "end": 30,
              "probability": 0.75807965,
              "start": 23,
              "text": "ä¸­å›½è®¡ç®—æœºå­¦ä¼š"
            }
          ],
          "å·²ä¸¾åŠæ¬¡æ•°": [
            {
              "end": 82,
              "probability": 0.4671307,
              "start": 80,
              "text": "4å±Š"
            }
          ],
          "æ‰¿åŠæ–¹": [
            {
              "end": 55,
              "probability": 0.700049,
              "start": 40,
              "text": "ä¸­å›½ä¸­æ–‡ä¿¡æ¯å­¦ä¼šè¯„æµ‹å·¥ä½œå§”å‘˜ä¼š"
            },
            {
              "end": 72,
              "probability": 0.61934763,
              "start": 56,
              "text": "ä¸­å›½è®¡ç®—æœºå­¦ä¼šè‡ªç„¶è¯­è¨€å¤„ç†ä¸“å§”ä¼š"
            },
            {
              "end": 39,
              "probability": 0.8292698,
              "start": 35,
              "text": "ç™¾åº¦å…¬å¸"
            }
          ]
        },
        "start": 0,
        "text": "2022è¯­è¨€ä¸æ™ºèƒ½æŠ€æœ¯ç«èµ›"
      }
    ]
  }
]
```
</details>


<details>
<summary>ğŸ‘‰  äº‹ä»¶æŠ½å–</summary>

```python
schema = {'åœ°éœ‡è§¦å‘è¯': ['åœ°éœ‡å¼ºåº¦', 'æ—¶é—´', 'éœ‡ä¸­ä½ç½®', 'éœ‡æºæ·±åº¦']}  # Define the schema for event extraction
model.set_schema(schema)
print(model.predict(tokenizer, "ä¸­å›½åœ°éœ‡å°ç½‘æ­£å¼æµ‹å®šï¼š5æœˆ16æ—¥06æ—¶08åˆ†åœ¨äº‘å—ä¸´æ²§å¸‚å‡¤åº†å¿(åŒ—çº¬24.34åº¦ï¼Œä¸œç»99.98åº¦)å‘ç”Ÿ3.5çº§åœ°éœ‡ï¼Œéœ‡æºæ·±åº¦10åƒç±³ã€‚"))
```

output:

```json
[
  {
    "åœ°éœ‡è§¦å‘è¯": [
      {
        "end": 58,
        "probability": 0.99774253,
        "relations": {
          "åœ°éœ‡å¼ºåº¦": [
            {
              "end": 56,
              "probability": 0.9980802,
              "start": 52,
              "text": "3.5çº§"
            }
          ],
          "æ—¶é—´": [
            {
              "end": 22,
              "probability": 0.98533,
              "start": 11,
              "text": "5æœˆ16æ—¥06æ—¶08åˆ†"
            }
          ],
          "éœ‡ä¸­ä½ç½®": [
            {
              "end": 50,
              "probability": 0.7874015,
              "start": 23,
              "text": "äº‘å—ä¸´æ²§å¸‚å‡¤åº†å¿(åŒ—çº¬24.34åº¦ï¼Œä¸œç»99.98åº¦)"
            }
          ],
          "éœ‡æºæ·±åº¦": [
            {
              "end": 67,
              "probability": 0.9937973,
              "start": 63,
              "text": "10åƒç±³"
            }
          ]
        },
        "start": 56,
        "text": "åœ°éœ‡"
      }
    ]
  }
]
```
</details>

<details>
<summary>ğŸ‘‰ è¯„è®ºè§‚ç‚¹æŠ½å–</summary>

```python
schema = {'è¯„ä»·ç»´åº¦': ['è§‚ç‚¹è¯', 'æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]']}  # Define the schema for opinion extraction
model.set_schema(schema)
print(model.predict(tokenizer, "åº—é¢å¹²å‡€ï¼Œå¾ˆæ¸…é™ï¼ŒæœåŠ¡å‘˜æœåŠ¡çƒ­æƒ…ï¼Œæ€§ä»·æ¯”å¾ˆé«˜ï¼Œå‘ç°æ”¶é“¶å°æœ‰æ’é˜Ÿ"))
```

output:

```json
[
  {
    "è¯„ä»·ç»´åº¦": [
      {
        "end": 20,
        "probability": 0.98170394,
        "relations": {
          "æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]": [
            {
              "probability": 0.9966142773628235,
              "text": "æ­£å‘"
            }
          ],
          "è§‚ç‚¹è¯": [
            {
              "end": 22,
              "probability": 0.95739645,
              "start": 21,
              "text": "é«˜"
            }
          ]
        },
        "start": 17,
        "text": "æ€§ä»·æ¯”"
      },
      {
        "end": 2,
        "probability": 0.9696847,
        "relations": {
          "æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]": [
            {
              "probability": 0.9982153177261353,
              "text": "æ­£å‘"
            }
          ],
          "è§‚ç‚¹è¯": [
            {
              "end": 4,
              "probability": 0.9945317,
              "start": 2,
              "text": "å¹²å‡€"
            }
          ]
        },
        "start": 0,
        "text": "åº—é¢"
      }
    ]
  }
]
```
</details>


<details>
<summary>ğŸ‘‰ æƒ…æ„Ÿåˆ†ç±»</summary>


```python
schema = "æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]"  # Define the schema for opinion extraction
model.set_schema(schema)
print(model.predict(tokenizer, "è¿™ä¸ªäº§å“ç”¨èµ·æ¥çœŸçš„å¾ˆæµç•…ï¼Œæˆ‘éå¸¸å–œæ¬¢"))
```

output:

```json
[
  {
    "æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]": [
      {
        "probability": 0.9990023970603943,
        "text": "æ­£å‘"
      }
    ]
  }
]
```
</details>

